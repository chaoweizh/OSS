{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd /stanford-corenlp-full-2018-10-05\n",
    "# java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tree import *\n",
    "from nltk import Tree\n",
    "from nltk.tag.stanford import StanfordPOSTagger,StanfordNERTagger\n",
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from collections import Counter\n",
    "import codecs\n",
    "import spacy\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#jar and model parameters need to be modified with your own path\n",
    "# jar = '/Users/chaowei/Downloads/stanford-postagger-full-2020-11-17/stanford-postagger.jar'\n",
    "# model = '/Users/chaowei/Downloads/stanford-postagger-full-2020-11-17/models/english-left3words-distsim.tagger'\n",
    "# stpos = StanfordPOSTagger(jar, model)\n",
    "\n",
    "# stanford_classifier = '/Users/chaowei/Downloads/stanford-ner-2020-11-17/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "# stanford_ner_path = '/Users/chaowei/Downloads/stanford-ner-2020-11-17/stanford-ner-4.2.0-javadoc.jar'\n",
    "# stner = StanfordNERTagger(stanford_classifier, stanford_ner_path)\n",
    "\n",
    "First_Pronouns = ['i', 'we', 'me','us','our','ours', 'ourself', 'ourselves', 'mine']\n",
    "Second_Pronouns = ['you', 'your','yours', 'yourself', 'yourselves']\n",
    "Third_Pronouns = ['he','his','him','she','her','hers','it','its','they','their','theirs','them', 'themself', 'themselves','itself']\n",
    "nouns_tags = ['NN', 'NNS', 'NNP', 'NNPS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stpos_tag_check(stpos_tags, spacy_ner_tags, triple, triple_tag):\n",
    "    indexes = triple[triple_tag]\n",
    "    collected_person = []\n",
    "    for index in range(indexes[0], indexes[1]):\n",
    "        stpos_tag = stpos_tags[index]\n",
    "        spacy_ner_tag = spacy_ner_tags[index] \n",
    "        if len(str(spacy_ner_tag)) != 0:  \n",
    "            collected_person.append(4)              \n",
    "        else:\n",
    "                collected_person.append(0)\n",
    "    return collected_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_object(varible):\n",
    "    if len(varible) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        if 1 in varible:\n",
    "            return 1\n",
    "        elif 2 in varible:\n",
    "            return 2\n",
    "        elif 3 in varible:\n",
    "            return 3\n",
    "        elif len(Counter(varible)) > 1:\n",
    "            while 0 in varible:       \n",
    "                varible.remove(0)  \n",
    "            #print varible,'varible'\n",
    "            return Counter(varible).most_common(1)[0][0]\n",
    "        else:\n",
    "            return Counter(varible).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persons_check(triple, stpos_tags, spacy_ner_tags):\n",
    "    tokenized_triple = [word_tokenize(triple['subject']),\n",
    "                        word_tokenize(triple['relation']), \n",
    "                        word_tokenize(triple['object'])]\n",
    "    triple_tag = ['subjectSpan', \n",
    "                 'relationSpan',\n",
    "                 'objectSpan']\n",
    "    subject_person = [] \n",
    "    for element in tokenized_triple[0]:       \n",
    "        if element in First_Pronouns:\n",
    "            subject_person.append(1)\n",
    "        elif element in Second_Pronouns:\n",
    "            subject_person.append(2)\n",
    "        elif element in Third_Pronouns:\n",
    "            subject_person.append(3)\n",
    "        elif len(stpos_tag_check(stpos_tags, spacy_ner_tags, triple, triple_tag[0])) != 0:\n",
    "            subject_person.append(Counter([a for a in stpos_tag_check(stpos_tags, spacy_ner_tags, triple, triple_tag[0]) if a != None]).most_common(1)[0][0]) \n",
    "        else:\n",
    "            subject_person.append(0)    \n",
    "    \n",
    "    object_person = []\n",
    "    for element in tokenized_triple[2]:\n",
    "        if element in First_Pronouns:        \n",
    "            object_person.append(1)\n",
    "        elif element in Second_Pronouns:\n",
    "            object_person.append(2)\n",
    "        elif element in Third_Pronouns:\n",
    "            object_person.append(3)\n",
    "        elif len(stpos_tag_check(stpos_tags, spacy_ner_tags, triple, triple_tag[2])) != 0:\n",
    "            object_person.append(Counter([a for a in stpos_tag_check(stpos_tags, spacy_ner_tags, triple, triple_tag[2]) if a != None]).most_common(1)[0][0]) \n",
    "        else:\n",
    "            object_person.append(0)\n",
    "    \n",
    "    subject_person = run_object(subject_person) \n",
    "    object_person = run_object(object_person)\n",
    "\n",
    "    return subject_person, object_person, triple['subjectSpan'][0], triple['objectSpan'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            ############# all tenses labels##############\n",
    "            ##########  Future Perfect Continuous --------> 1\n",
    "            ##########        Future Perfect      --------> 2\n",
    "            ##########       Future Continuous    --------> 3\n",
    "            ##########          Future Simple     --------> 4\n",
    "            ##########  present Perfect Continuous --------> 5\n",
    "            ##########        present Perfect      --------> 6\n",
    "            ##########       present Continuous    --------> 7\n",
    "            ##########          present Simple     --------> 8            \n",
    "            ##########  past Perfect Continuous --------> 9\n",
    "            ##########        past Perfect      --------> 10\n",
    "            ##########       past Continuous    --------> 11\n",
    "            ##########          past Simple     --------> 12\n",
    "            ##########          Undetectable      --------> 0\n",
    "            #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tense_detector(stpos_tags, openie, sub_location, obj_location):\n",
    "    all_tense = []\n",
    "    for triple in openie:\n",
    "        if sub_location == triple['subjectSpan'][0] and obj_location == triple['objectSpan'][0]:\n",
    "            predicate_index = triple['relationSpan']\n",
    "            only_stpos_tag = [v for k,v in stpos_tags[predicate_index[0]:predicate_index[1]+1]]\n",
    "\n",
    "            if \"MD\" in [w for w in only_stpos_tag]:\n",
    "                if set([\"VB\", \"VBN\", \"VBG\"]).issubset(set(only_stpos_tag)) == True: #Future Perfect Continuous\n",
    "                    all_tense.append(1)\n",
    "                    #print 'Future Perfect Continuous'\n",
    "                    \n",
    "                elif set([\"VB\", \"VBN\"]).issubset(set(only_stpos_tag)) == True: #Future Perfect \n",
    "                    all_tense.append(2)\n",
    "                    #print 'Future Perfect'\n",
    "                elif set([\"VB\", \"VBG\"]).issubset(set(only_stpos_tag)) == True: #Future Continuous\n",
    "                    all_tense.append(3)\n",
    "                    #print 'Future Continuous'\n",
    "                else: #Future\n",
    "                    all_tense.append(4)\n",
    "                    #print 'Future'\n",
    "\n",
    "            elif \"VBD\" in [w for w in only_stpos_tag]:\n",
    "                if set([\"VBN\", \"VBG\"]).issubset(set(only_stpos_tag)) == True: #Past Perfect Continuous\n",
    "                    all_tense.append(9)\n",
    "                    #print 'Past Perfect Continuous'\n",
    "                elif set([\"VBN\"]).issubset(set(only_stpos_tag)) == True: #Past Perfect \n",
    "                    all_tense.append(10)\n",
    "                    #print 'Past Perfect'\n",
    "                elif set([\"VBG\"]).issubset(set(only_stpos_tag)) == True: #Past Continuous\n",
    "                    all_tense.append(11)\n",
    "                    #print 'Past Continuous'\n",
    "                else: #Past\n",
    "                    all_tense.append(12)\n",
    "                    #print 'Past'\n",
    "\n",
    "            elif \"VBP\" or \"VBZ\" in [w for w in only_stpos_tag]:\n",
    "                if set([\"VBN\", \"VBG\"]).issubset(set(only_stpos_tag)) == True: #present Perfect Continuous\n",
    "                    all_tense.append(5)\n",
    "                    #print 'present Perfect Continuous'\n",
    "                elif set([\"VBN\"]).issubset(set(only_stpos_tag)) == True: #present Perfect \n",
    "                    all_tense.append(6)\n",
    "                    #print 'present Perfect'\n",
    "                elif set([\"VBG\"]).issubset(set(only_stpos_tag)) == True: #present Continuous\n",
    "                    all_tense.append(7)\n",
    "                    #print 'present Continuous'\n",
    "                else:#present \n",
    "                    all_tense.append(8)\n",
    "                    #print 'present'\n",
    "\n",
    "            else:\n",
    "                all_tense.append(0)\n",
    "                #print 'undetectable'\n",
    "            \n",
    "    if len(Counter(all_tense)) > 1:\n",
    "        all_tense = [max([a for a,b in Counter(all_tense).items() if a != 0])]\n",
    "    else: \n",
    "        all_tense = [a for a,b in Counter(all_tense).items()]\n",
    "    \n",
    "    return all_tense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tense_detector(stpos_tags, openie, sub_location, obj_location):\n",
    "    all_tense = []\n",
    "    for triple in openie:\n",
    "        if sub_location == triple['subjectSpan'][0] and obj_location == triple['objectSpan'][0]:\n",
    "            predicate_index = triple['relationSpan']\n",
    "            only_stpos_tag = [v for v in stpos_tags[predicate_index[0]:predicate_index[-1]]]\n",
    "                              \n",
    "            if \"MD\" in [w for w in only_stpos_tag]: \n",
    "                if set([\"VB\", \"VBN\", \"VBG\"]).issubset(set(only_stpos_tag)) == True: #Future Perfect Continuous\n",
    "                    all_tense.append(1) \n",
    "                elif set([\"VB\", \"VBN\"]).issubset(set(only_stpos_tag)) == True: #Future Perfect \n",
    "                    all_tense.append(2)\n",
    "                elif set([\"VB\", \"VBG\"]).issubset(set(only_stpos_tag)) == True: #Future Continuous\n",
    "                    all_tense.append(3)\n",
    "                else: #Future\n",
    "                    all_tense.append(4)\n",
    "                              \n",
    "            elif \"VBP\" or \"VBZ\" in [w for w in only_stpos_tag]:\n",
    "                if set([\"VBN\", \"VBG\"]).issubset(set(only_stpos_tag)) == True: #present Perfect Continuous\n",
    "                    all_tense.append(5)\n",
    "                elif set([\"VBN\"]).issubset(set(only_stpos_tag)) == True: #present Perfect \n",
    "                    all_tense.append(6)\n",
    "                elif set([\"VBG\"]).issubset(set(only_stpos_tag)) == True: #present Continuous\n",
    "                    all_tense.append(7)\n",
    "                else:#present \n",
    "                    all_tense.append(8)\n",
    "                              \n",
    "            elif \"VBD\" in [w for w in only_stpos_tag]:\n",
    "                if set([\"VBN\", \"VBG\"]).issubset(set(only_stpos_tag)) == True: #Past Perfect Continuous\n",
    "                    all_tense.append(9)\n",
    "                elif set([\"VBN\"]).issubset(set(only_stpos_tag)) == True: #Past Perfect \n",
    "                    all_tense.append(10)\n",
    "                elif set([\"VBG\"]).issubset(set(only_stpos_tag)) == True: #Past Continuous\n",
    "                    all_tense.append(11)\n",
    "                else: #Past\n",
    "                    all_tense.append(12)       \n",
    "\n",
    "            else:\n",
    "                all_tense.append(0) # 'undetectable'\n",
    "        else:\n",
    "            continue\n",
    "   \n",
    "    if len(all_tense) > 0: \n",
    "        tense = min(all_tense)\n",
    "    else: \n",
    "        tense = 0\n",
    "    \n",
    "    return tense\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "spacy_ner = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def triple_selection(input_file, output_file): # input_file is the raw dataset; \n",
    "                                               #output_file is used to stored the selected triple \n",
    "                                               #in forms of viewpoints and tense\n",
    "    f1 = codecs.open(input_file, encoding='utf-8')# after executing obj.txt, sub.txt need to be processed by modifying open(\"MPQA/obj.txt\") with open(\"MPQA/subj.txt\")\n",
    "    uni_lines = f1.readlines()\n",
    "    sentence_number = -1\n",
    "    all_data_sub_person = []\n",
    "    all_data_obj_person = []\n",
    "    all_data_tense = []\n",
    "    all_data_sub_obj = []\n",
    "    all_data_sub_tense = []\n",
    "    all_data_tense_obj = []\n",
    "    all_data_triple = []\n",
    "    for line in uni_lines:    \n",
    "        sentence_number += 1\n",
    "        line = line.replace(\"\\n\", '')\n",
    "        line = line.replace(\")\", '')\n",
    "        line = line.replace(\"(\", '')\n",
    "        #print (\"No.\", sentence_number+1,\"sentense is being processed.------>\", line)\n",
    "        try:\n",
    "            res = nlp.annotate(line.lower(),\n",
    "                                       properties={\n",
    "                                           'annotators': 'depparse, parse, openie',\n",
    "                                           'outputFormat': 'json',\"triple.strict\":\"true\"\n",
    "                                       })\n",
    "\n",
    "            parse = res[\"sentences\"][0][\"parse\"]\n",
    "            openie = res[\"sentences\"][0][\"openie\"]\n",
    "\n",
    "            stpos_tags = [a.tag_ for a in spacy_ner(line)]\n",
    "            pos_tags = [a[1] for a in pos_tag(word_tokenize(line))]\n",
    "            spacy_ner_tags = [a.ent_type_ for a in spacy_ner(line)]\n",
    "\n",
    "        except:\n",
    "            #print(\"No.\",sentence_number+1,\"sentence can't be analyzed by corenlp\")\n",
    "            continue\n",
    "\n",
    "        sum_subs = []\n",
    "        sum_subs_location = []\n",
    "        sum_objs_location = []\n",
    "        sum_objs = []\n",
    "        sum_verbs= []\n",
    "        sub_obj = []\n",
    "        sub_tense = []\n",
    "        tense_obj = []\n",
    "        sub_tense_obj = []\n",
    "        try:\n",
    "            for triple in openie:\n",
    "                sub_person, obj_person, sub_location, obj_location = persons_check(triple, stpos_tags, spacy_ner_tags)\n",
    "\n",
    "        # experiment 1 : test subject only\n",
    "                sum_subs_location.append(sub_location)\n",
    "                sum_objs_location.append(obj_location)\n",
    "                sum_subs.append(sub_person)\n",
    "\n",
    "        # experiment 2 : test object only\n",
    "                sum_objs.append(obj_person) \n",
    "\n",
    "        except:\n",
    "            #print(\"subject or coresponding object-list is failed to be extracted\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # experiment 1 : test subject only \n",
    "            external_sub = sum_subs[sum_subs_location.index(min(sum_subs_location))] \n",
    "            # experiment 2 : test object only\n",
    "\n",
    "            select_sub_o_location = [triple['objectSpan'][0] for triple in openie if min(sum_subs_location) == triple['subjectSpan'][0]]\n",
    "\n",
    "            selected_objs_person = sum_objs[sum_objs_location.index(max(select_sub_o_location))]   \n",
    "\n",
    "            tense = tense_detector(pos_tags, openie, min(sum_subs_location), max(select_sub_o_location))\n",
    "\n",
    "\n",
    "            all_data_triple.append([external_sub]+ [tense]+ [selected_objs_person])\n",
    "        except:\n",
    "            #print(\"No.\",sentence_number+1,\"sentence fails to be processed\")\n",
    "            continue\n",
    "\n",
    "        #print('*********************************************************************************************************************')\n",
    "        if len([external_sub]+ [tense]+[selected_objs_person]) > 3:\n",
    "            print ('no triples can be extracted from the sentence:', line)\n",
    "    f.close()\n",
    "    outputs = open(output_file, 'w')\n",
    "    outputs.write(str(all_data_triple))\n",
    "    outputs.close()\n",
    "    #return all_data_triple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to txt files\n",
    "triple_selection(\"MPQA/obj-samples.txt\", 'temp_outputs/obj_triples.txt') # for objective dataset\n",
    "triple_selection(\"MPQA/subj-samples.txt\", 'temp_outputs/subj_triples.txt')# for subjective dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataprocessing(file_location):\n",
    "\n",
    "    fd = open(file_location, \"r\")\n",
    "    all_data = (fd.readlines())[0][2:-2].split('], [')\n",
    "\n",
    "    all_subs = []\n",
    "    all_tenses = []\n",
    "    all_objs = []\n",
    "    all_subs_tenses = []\n",
    "    all_subs_objs = []\n",
    "    all_tenses_objs = []\n",
    "    \n",
    "    for tem_triple in (all_data):  \n",
    "        \n",
    "        tem_triple_ = tem_triple.split(', ')\n",
    "        all_subs.append((tem_triple_[0]))\n",
    "        all_tenses.append((tem_triple_[1]))  \n",
    "        all_objs.append((tem_triple_[-1]))\n",
    "        all_subs_tenses.append((tem_triple_[0], tem_triple_[1]))\n",
    "        all_subs_objs.append((tem_triple_[0],tem_triple_[-1]))\n",
    "        all_tenses_objs.append((tem_triple_[1], tem_triple_[-1]))\n",
    "\n",
    "    return all_subs_tenses, all_subs_objs, all_tenses_objs, all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjective dataset\n",
    "S_all_subs_tenses, S_all_subs_objs, S_all_tenses_objs, S_data = dataprocessing('temp_outputs/subj_triples.txt')\n",
    "\n",
    "#  objective dataset\n",
    "O_all_subs_tenses, O_all_subs_objs, O_all_tenses_objs, O_data = dataprocessing('temp_outputs/obj_triples.txt')\n",
    "\n",
    "# print('S_all_subs_tenses', Counter(S_all_subs_tenses).items()) \n",
    "# print('O_all_subs_tenses', Counter(O_all_subs_tenses).items()) \n",
    "# print('****************************************************************')\n",
    "# print('S_all_subs_objs', Counter(S_all_subs_objs).items()) \n",
    "# print('O_all_subs_objs', Counter(O_all_subs_objs).items()) \n",
    "# print('****************************************************************')\n",
    "# print('S_all_tenses_objs', Counter(S_all_tenses_objs).items()) \n",
    "# print('O_all_tenses_objs', Counter(O_all_tenses_objs).items()) \n",
    "# print('****************************************************************')\n",
    "# print('S_data', Counter(S_data).items()) \n",
    "# print('O_data', Counter(O_data).items()) \n",
    "# print('****************************************************************')\n",
    "# print(S_data,len(S_data))\n",
    "# print(O_data,len(O_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S for sv [(('3', '11'), 1), (('0', '2'), 1), (('4', '4'), 2), (('0', '3'), 1), (('1', '12'), 11), (('1', '11'), 1), (('1', '10'), 3), (('1', '7'), 8)]\n",
      "O for sv [(('3', '10'), 4), (('2', '11'), 1)]\n",
      "S for vo [(('3', '0'), 1), (('4', '1'), 1), (('2', '0'), 1), (('12', '2'), 1)]\n",
      "O for vo [(('10', '4'), 3), (('12', '4'), 8), (('11', '4'), 1), (('6', '1'), 1), (('11', '3'), 2), (('10', '3'), 2)]\n",
      "S for so [(('4', '2'), 1), (('2', '1'), 1), (('2', '4'), 2)]\n",
      "O for so [(('4', '2'), 1), (('2', '1'), 1), (('2', '4'), 2)]\n",
      "s triple [('0, 4, 1', 1), ('2, 7, 3', 1), ('2, 6, 3', 1), ('1, 12, 3', 3), ('1, 12, 0', 8), ('4, 4, 0', 2), ('0, 3, 0', 1), ('0, 12, 1', 2), ('0, 12, 2', 1), ('3, 11, 0', 1), ('0, 2, 0', 1), ('2, 12, 3', 2), ('4, 7, 2', 1), ('1, 10, 0', 3), ('1, 7, 3', 1), ('2, 6, 4', 1), ('1, 11, 0', 1), ('2, 4, 3', 2), ('2, 4, 2', 2), ('2, 8, 4', 1), ('1, 7, 0', 7), ('2, 8, 1', 1)]\n",
      "o triple [('0, 10, 4', 2), ('4, 12, 4', 1), ('0, 11, 4', 1), ('0, 6, 1', 1), ('4, 6, 3', 1), ('0, 11, 3', 2), ('4, 7, 0', 3), ('3, 12, 4', 3), ('3, 12, 3', 10), ('3, 12, 1', 1), ('3, 10, 0', 3), ('0, 12, 4', 4), ('3, 10, 4', 1), ('2, 11, 0', 1), ('3, 7, 4', 3), ('3, 7, 3', 22), ('0, 10, 3', 2), ('4, 7, 4', 1)]\n"
     ]
    }
   ],
   "source": [
    "#unique tuple - s v\n",
    "countered_S = Counter(S_all_subs_tenses).items()\n",
    "countered_O = Counter(O_all_subs_tenses).items()\n",
    "\n",
    "sub_triple_100 = [(a, b) for a, b in countered_S if a not in O_all_subs_tenses]\n",
    "print 'S for sv', sub_triple_100    \n",
    "\n",
    "obj_triple_100 = [(a, b) for a, b in countered_O if a not in S_all_subs_tenses]\n",
    "print 'O for sv', obj_triple_100 \n",
    "\n",
    "#unique tuple - v o\n",
    "countered_S = Counter(S_all_tenses_objs).items()\n",
    "countered_O = Counter(O_all_tenses_objs).items()\n",
    "\n",
    "sub_triple_100 = [(a, b) for a, b in countered_S if a not in O_all_tenses_objs]\n",
    "print 'S for vo', sub_triple_100    \n",
    "\n",
    "obj_triple_100 = [(a, b) for a, b in countered_O if a not in S_all_tenses_objs]\n",
    "print 'O for vo', obj_triple_100 \n",
    "#unique tuple - s o\n",
    "countered_S = Counter(S_all_subs_objs).items()\n",
    "countered_O = Counter(O_all_subs_objs).items()\n",
    "\n",
    "sub_triple_100 = [(a, b) for a, b in countered_S if a not in O_all_subs_objs]\n",
    "print 'S for so', sub_triple_100    \n",
    "\n",
    "obj_triple_100 = [(a, b) for a, b in countered_O if a not in S_all_subs_objs]\n",
    "print 'O for so', sub_triple_100   \n",
    "\n",
    "# unique triples\n",
    "countered_S = Counter(S_data).items()\n",
    "countered_O = Counter(O_data).items()\n",
    "\n",
    "sub_triple_100 = [(a, b) for a, b in countered_S if a not in O_data]\n",
    "print 's triple', sub_triple_100     \n",
    "\n",
    "obj_triple_100 = [(a, b) for a, b in countered_O if a not in S_data]\n",
    "print 'o triple', obj_triple_100  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when threshold is 0.7  subjective patterns are [('1, 6, 0', 7, 3, 0.7), ('2, 8, 3', 7, 3, 0.7)]\n",
      "when threshold is 0.7 objective patterns are [('0, 6, 0', 110, 282, 0.7193877551020408), ('0, 8, 3', 152, 364, 0.7054263565891473)]\n",
      "when threshold is 0.725  subjective patterns are [('0, 8, 1', 28, 10, 0.7368421052631579)]\n",
      "when threshold is 0.725 objective patterns are [('3, 7, 0', 22, 64, 0.7441860465116279), ('3, 8, 4', 6, 17, 0.7391304347826086)]\n",
      "when threshold is 0.75  subjective patterns are [('1, 8, 4', 3, 1, 0.75)]\n",
      "when threshold is 0.75 objective patterns are [('4, 8, 3', 2, 6, 0.75), ('4, 8, 0', 17, 52, 0.7536231884057971), ('0, 10, 0', 6, 20, 0.7692307692307693)]\n",
      "when threshold is 0.775  subjective patterns are [('1, 4, 0', 7, 2, 0.7777777777777778), ('3, 8, 2', 7, 2, 0.7777777777777778)]\n",
      "when threshold is 0.775 objective patterns are [('4, 6, 0', 2, 7, 0.7777777777777778), ('0, 8, 4', 20, 78, 0.7959183673469388)]\n",
      "when threshold is 0.8  subjective patterns are [('3, 8, 1', 9, 2, 0.8181818181818182), ('2, 8, 0', 36, 8, 0.8181818181818182)]\n",
      "when threshold is 0.8 objective patterns are [('0, 6, 4', 2, 9, 0.8181818181818182), ('3, 12, 0', 9, 40, 0.8163265306122449), ('0, 7, 3', 14, 56, 0.8), ('0, 12, 3', 5, 20, 0.8)]\n",
      "when threshold is 0.825  subjective patterns are [('0, 4, 2', 5, 1, 0.8333333333333334)]\n",
      "when threshold is 0.825 objective patterns are [('3, 6, 0', 16, 83, 0.8383838383838383)]\n",
      "when threshold is 0.85  subjective patterns are [('2, 4, 0', 12, 2, 0.8571428571428571), ('2, 8, 2', 12, 2, 0.8571428571428571)]\n",
      "when threshold is 0.85 objective patterns are []\n",
      "when threshold is 0.875  subjective patterns are [('2, 7, 0', 7, 1, 0.875), ('2, 6, 0', 7, 1, 0.875)]\n",
      "when threshold is 0.875 objective patterns are [('3, 6, 4', 1, 8, 0.8888888888888888)]\n",
      "when threshold is 0.9  subjective patterns are []\n",
      "when threshold is 0.9 objective patterns are [('3, 4, 3', 1, 10, 0.9090909090909091), ('3, 8, 3', 18, 184, 0.9108910891089109)]\n",
      "when threshold is 0.925  subjective patterns are []\n",
      "when threshold is 0.925 objective patterns are [('3, 6, 3', 1, 22, 0.9565217391304348)]\n",
      "when threshold is 1  subjective patterns are []\n",
      "when threshold is 1 objective patterns are []\n"
     ]
    }
   ],
   "source": [
    "pair_ST = [S_all_subs_tenses, O_all_subs_tenses]   \n",
    "pair_SO = [S_all_subs_objs, O_all_subs_objs]\n",
    "pair_TO = [S_all_tenses_objs, O_all_tenses_objs]\n",
    "pair_STO = [S_data, O_data]\n",
    "    \n",
    "countered_S = Counter(pair_STO[0]).items()\n",
    "countered_O = Counter(pair_STO[1]).items()\n",
    "\n",
    "############## possibility calculations ###############        ######(1,1,1) ---> sub for 0 times\n",
    "all_S_percentages = [] #### for subjective dataset         ######        ---> obj for 3 times  \n",
    "for item_s, num_s in countered_S:\n",
    "    try:\n",
    "        num_o = [b for a, b in countered_O if a==item_s][0]\n",
    "        percentage_S = float(num_s)/(num_s+num_o) #\n",
    "        all_S_percentages.append((item_s,percentage_S, num_s, num_o))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "all_O_percentages = [] #### for objective dataset\n",
    "for item_o, num_o in countered_O:\n",
    "    try:\n",
    "        num_s = [b for a, b in countered_S if a==item_o][0]\n",
    "        percentage_O = float(num_o)/(num_s+num_o)\n",
    "        all_O_percentages.append((item_o,percentage_O, num_s, num_o))\n",
    "    except:\n",
    "        continue\n",
    "#print all_S_percentages\n",
    "#print all_O_percentages\n",
    "\n",
    "thresholds = [0.7, 0.725, 0.75, 0.775, 0.8, 0.825, 0.85, 0.875, 0.9, 0.925, 1]\n",
    "for threshold in thresholds:\n",
    "    subjective_patterns = []\n",
    "    objective_patterns = []\n",
    "    for item_s, percentage_S, num_s, num_o in all_S_percentages:\n",
    "\n",
    "        if percentage_S >= threshold and percentage_S < thresholds[(thresholds.index(threshold)+1)]:  \n",
    "              # if possibility of being a subjective one is larger than threshold, \n",
    "            subjective_patterns.append(((item_s), num_s, num_o, percentage_S,))    # the current item will be selected as a subjective pattern\n",
    "   \n",
    "\n",
    "    for item_s, percentage_O, num_s, num_o in all_O_percentages:    \n",
    "        if percentage_O >= threshold and percentage_O < thresholds[(thresholds.index(threshold)+1)]:  \n",
    "              # if possibility of being a subjective one is larger than threshold, \n",
    "            objective_patterns.append(((item_s), num_s, num_o, percentage_O)) \n",
    "    #             if percentage_S <= 0.5:  \n",
    "    #                 if item_s not in objective_patterns:      # if possibility of being a subjective one is smaller than threshold,\n",
    "    #                     objective_patterns.append(item_s)     # the current item will be selected as a objective pattern   \n",
    "\n",
    "    print 'when threshold is', threshold, ' subjective patterns are', subjective_patterns\n",
    "    print 'when threshold is', threshold, 'objective patterns are', objective_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when the threshold =  0.7\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      Measure      |   Mean  | variance | standard deviation |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      accuracy     | 0.76182 | 0.00077  |      0.02776       |\n",
      "|  precision_S_all  | 0.76878 | 0.00992  |      0.09959       |\n",
      "|  precision_O_all  | 0.76158 | 0.00084  |      0.02892       |\n",
      "|    recall_S_all   | 0.24793 | 0.00493  |      0.07021       |\n",
      "|    recall_O_all   | 0.96938 | 0.00026  |      0.01608       |\n",
      "|    fscore_S_all   | 0.36974 | 0.00672  |      0.08195       |\n",
      "|    fscore_O_all   | 0.85263 | 0.00035  |       0.0188       |\n",
      "| average precision | 0.76518 | 0.00538  |      0.06425       |\n",
      "|   average recall  | 0.60866 | 0.00259  |      0.04315       |\n",
      "|   average fscore  | 0.61119 | 0.00353  |      0.05037       |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "when the threshold =  0.725\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      Measure      |   Mean  | variance | standard deviation |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      accuracy     | 0.79746 | 0.00177  |      0.04213       |\n",
      "|  precision_S_all  | 0.76174 | 0.01113  |      0.10548       |\n",
      "|  precision_O_all  | 0.80505 | 0.00216  |      0.04651       |\n",
      "|    recall_S_all   | 0.40256 |  0.0136  |      0.11664       |\n",
      "|    recall_O_all   | 0.95066 | 0.00071  |      0.02672       |\n",
      "|    fscore_S_all   |  0.5161 | 0.01199  |      0.10949       |\n",
      "|    fscore_O_all   | 0.87085 | 0.00082  |      0.02867       |\n",
      "| average precision | 0.78339 | 0.00664  |       0.076        |\n",
      "|   average recall  | 0.67661 | 0.00716  |      0.07168       |\n",
      "|   average fscore  | 0.69347 |  0.0064  |      0.06908       |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "when the threshold =  0.75\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      Measure      |   Mean  | variance | standard deviation |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      accuracy     |  0.8114 |  0.0015  |      0.03869       |\n",
      "|  precision_S_all  | 0.77268 | 0.01222  |      0.11054       |\n",
      "|  precision_O_all  |  0.8201 | 0.00165  |      0.04066       |\n",
      "|    recall_S_all   | 0.44761 | 0.01156  |      0.10752       |\n",
      "|    recall_O_all   | 0.94841 | 0.00089  |      0.02987       |\n",
      "|    fscore_S_all   | 0.55846 | 0.00946  |      0.09726       |\n",
      "|    fscore_O_all   | 0.87887 | 0.00074  |      0.02719       |\n",
      "| average precision | 0.79639 | 0.00694  |       0.0756       |\n",
      "|   average recall  | 0.69801 | 0.00623  |       0.0687       |\n",
      "|   average fscore  | 0.71866 |  0.0051  |      0.06222       |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "when the threshold =  0.775\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      Measure      |   Mean  | variance | standard deviation |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      accuracy     | 0.82658 | 0.00183  |       0.0428       |\n",
      "|  precision_S_all  | 0.79544 | 0.01528  |      0.12363       |\n",
      "|  precision_O_all  | 0.83331 | 0.00203  |      0.04501       |\n",
      "|    recall_S_all   | 0.45999 | 0.01337  |      0.11561       |\n",
      "|    recall_O_all   | 0.95658 |  0.0009  |      0.03005       |\n",
      "|    fscore_S_all   |  0.5736 | 0.01129  |      0.10626       |\n",
      "|    fscore_O_all   | 0.88987 | 0.00088  |      0.02965       |\n",
      "| average precision | 0.81437 | 0.00866  |      0.08432       |\n",
      "|   average recall  | 0.70829 | 0.00713  |      0.07283       |\n",
      "|   average fscore  | 0.73173 | 0.00609  |      0.06796       |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "when the threshold =  0.8\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      Measure      |   Mean  | variance | standard deviation |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      accuracy     |  0.8269 | 0.00212  |      0.04603       |\n",
      "|  precision_S_all  | 0.80898 |  0.0168  |      0.12961       |\n",
      "|  precision_O_all  | 0.83168 | 0.00244  |      0.04938       |\n",
      "|    recall_S_all   | 0.47747 | 0.01991  |      0.14111       |\n",
      "|    recall_O_all   | 0.95616 | 0.00114  |      0.03371       |\n",
      "|    fscore_S_all   | 0.58753 | 0.01594  |      0.12625       |\n",
      "|    fscore_O_all   | 0.88854 | 0.00103  |      0.03213       |\n",
      "| average precision | 0.82033 | 0.00962  |      0.08949       |\n",
      "|   average recall  | 0.71681 | 0.01052  |      0.08741       |\n",
      "|   average fscore  | 0.73803 | 0.00849  |      0.07919       |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "when the threshold =  0.825\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      Measure      |   Mean  | variance | standard deviation |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      accuracy     | 0.83935 | 0.00301  |      0.05488       |\n",
      "|  precision_S_all  | 0.76301 | 0.02979  |      0.17261       |\n",
      "|  precision_O_all  | 0.85646 | 0.00336  |      0.05798       |\n",
      "|    recall_S_all   | 0.45712 | 0.03329  |      0.18246       |\n",
      "|    recall_O_all   | 0.95096 | 0.00173  |      0.04154       |\n",
      "|    fscore_S_all   | 0.54496 | 0.02416  |      0.15545       |\n",
      "|    fscore_O_all   | 0.89979 | 0.00143  |      0.03786       |\n",
      "| average precision | 0.80974 | 0.01658  |       0.1153       |\n",
      "|   average recall  | 0.70404 | 0.01751  |       0.112        |\n",
      "|   average fscore  | 0.72237 |  0.0128  |      0.09665       |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "when the threshold =  0.85\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      Measure      |   Mean  | variance | standard deviation |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      accuracy     | 0.85355 |  0.0038  |      0.06163       |\n",
      "|  precision_S_all  | 0.68231 | 0.05119  |      0.22625       |\n",
      "|  precision_O_all  | 0.88436 | 0.00383  |      0.06192       |\n",
      "|    recall_S_all   | 0.42604 | 0.05193  |      0.22787       |\n",
      "|    recall_O_all   | 0.94687 | 0.00256  |      0.05062       |\n",
      "|    fscore_S_all   | 0.47612 | 0.02738  |      0.16547       |\n",
      "|    fscore_O_all   | 0.91268 | 0.00166  |      0.04071       |\n",
      "| average precision | 0.78333 | 0.02751  |      0.14409       |\n",
      "|   average recall  | 0.68646 | 0.02724  |      0.13924       |\n",
      "|   average fscore  |  0.6944 | 0.01452  |      0.10309       |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "when the threshold =  0.875\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      Measure      |   Mean  | variance | standard deviation |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      accuracy     | 0.86391 | 0.00376  |      0.06133       |\n",
      "|  precision_S_all  | 0.52319 | 0.01722  |      0.13122       |\n",
      "|  precision_O_all  | 0.91108 | 0.00379  |      0.06157       |\n",
      "|    recall_S_all   | 0.50936 | 0.05989  |      0.24472       |\n",
      "|    recall_O_all   |  0.9312 | 0.00146  |       0.0382       |\n",
      "|    fscore_S_all   | 0.48609 | 0.02208  |       0.1486       |\n",
      "|    fscore_O_all   | 0.91977 | 0.00159  |      0.03985       |\n",
      "| average precision | 0.71713 |  0.0105  |       0.0964       |\n",
      "|   average recall  | 0.72028 | 0.03067  |      0.14146       |\n",
      "|   average fscore  | 0.70293 | 0.01183  |      0.09423       |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "when the threshold =  0.9\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      Measure      |   Mean  | variance | standard deviation |\n",
      "+-------------------+---------+----------+--------------------+\n",
      "|      accuracy     | 0.86966 | 0.00306  |      0.05529       |\n",
      "|  precision_S_all  | 0.56485 | 0.01049  |      0.10243       |\n",
      "|  precision_O_all  | 0.91012 | 0.00333  |      0.05774       |\n",
      "|    recall_S_all   | 0.49273 |  0.0501  |      0.22383       |\n",
      "|    recall_O_all   | 0.93907 | 0.00273  |      0.05223       |\n",
      "|    fscore_S_all   |  0.5024 | 0.01927  |      0.13882       |\n",
      "|    fscore_O_all   | 0.92229 | 0.00202  |      0.04493       |\n",
      "| average precision | 0.73748 | 0.00691  |      0.08008       |\n",
      "|   average recall  |  0.7159 | 0.02641  |      0.13803       |\n",
      "|   average fscore  | 0.71235 | 0.01064  |      0.09188       |\n",
      "+-------------------+---------+----------+--------------------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when the threshold =  0.925\n",
      "+-------------------+------+----------+--------------------+\n",
      "|      Measure      | Mean | variance | standard deviation |\n",
      "+-------------------+------+----------+--------------------+\n",
      "|      accuracy     | nan  |   nan    |        nan         |\n",
      "|  precision_S_all  | nan  |   nan    |        nan         |\n",
      "|  precision_O_all  | nan  |   nan    |        nan         |\n",
      "|    recall_S_all   | nan  |   nan    |        nan         |\n",
      "|    recall_O_all   | nan  |   nan    |        nan         |\n",
      "|    fscore_S_all   | nan  |   nan    |        nan         |\n",
      "|    fscore_O_all   | nan  |   nan    |        nan         |\n",
      "| average precision | nan  |   nan    |        nan         |\n",
      "|   average recall  | nan  |   nan    |        nan         |\n",
      "|   average fscore  | nan  |   nan    |        nan         |\n",
      "+-------------------+------+----------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "########cross fold testing##########\n",
    "import numpy as np\n",
    "import random\n",
    "import prettytable as pt\n",
    "\n",
    "for threshold in [0.7, 0.725, 0.75, 0.775, 0.8, 0.825, 0.85, 0.875, 0.9, 0.925]:\n",
    "    tb = pt.PrettyTable()\n",
    "    subjective_result = []\n",
    "    objective_result = []\n",
    "    precision_S_all = []\n",
    "    precision_O_all = []\n",
    "    recall_S_all = []\n",
    "    recall_O_all = []\n",
    "    fscore_S_all = []\n",
    "    fscore_O_all = []\n",
    "    for b in range(100):\n",
    "        sub_accuracy = 0\n",
    "        obj_accuracy = 0\n",
    "        count_sub = 0\n",
    "        count_obj = 0\n",
    "        #print len(S_data), len(O_data)\n",
    "        for a in range(10):\n",
    "            S_data_sorting = sorted(S_data, key=lambda k: random.random()) # randomly sort data points\n",
    "            O_data_sorting = sorted(O_data, key=lambda k: random.random())\n",
    "            splitted_S_data = [S_data_sorting[i:i + (len(S_data)/10)+1] for i in range(0, len(S_data_sorting), (len(S_data)/10)+1)] #np.array(np.array_split(S_data_sorting,10,axis=0))\n",
    "            splitted_O_data = [O_data_sorting[i:i + (len(O_data)/10)+1] for i in range(0, len(O_data_sorting), (len(O_data)/10)+1)] #np.array(np.array_split(O_data_sorting,10,axis=0))\n",
    "\n",
    "            testing_S_data = splitted_S_data.pop(a)\n",
    "            testing_O_data = splitted_O_data.pop(a)\n",
    "            _training_S_data = splitted_S_data\n",
    "            _training_O_data = splitted_O_data\n",
    "\n",
    "            training_S_data = []\n",
    "            training_O_data = []  \n",
    "            for a in _training_S_data:\n",
    "                training_S_data.extend(a)  \n",
    "            for a in _training_O_data:\n",
    "                training_O_data.extend(a)\n",
    "\n",
    "            countered_S = Counter(training_S_data).items()\n",
    "            countered_O = Counter(training_O_data).items()\n",
    "\n",
    "        ############## possibility calculations ###############        ######(1,1,1) ---> sub for 0 times\n",
    "            all_S_percentages = [] #### for subjective dataset         ######        ---> obj for 3 times  \n",
    "            for item_s, num_s in countered_S:\n",
    "                try:\n",
    "                    num_o = [b for a, b in countered_O if a==item_s][0]\n",
    "                    percentage_S = float(num_s)/(num_s+num_o) #\n",
    "                    all_S_percentages.append((item_s,percentage_S))\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "\n",
    "            all_O_percentages = [] #### for objective dataset\n",
    "            for item_o, num_o in countered_O:\n",
    "                try:\n",
    "                    num_s = [b for a, b in countered_S if a==item_o][0]\n",
    "                    percentage_O = float(num_o)/(num_s+num_o)\n",
    "                    all_O_percentages.append((item_o,percentage_O))\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "\n",
    "    #         print all_S_percentages\n",
    "    #         print all_O_percentages\n",
    "\n",
    "            subjective_patterns = []\n",
    "            objective_patterns = []\n",
    "            for item_s, percentage_S in all_S_percentages:\n",
    "\n",
    "                if percentage_S >= threshold:  \n",
    "                    if item_s not in subjective_patterns:     # if possibility of being a subjective one is larger than threshold, \n",
    "                        subjective_patterns.append(item_s)    # the current item will be selected as a subjective pattern\n",
    "\n",
    "    #             if percentage_S <= 0.5:  \n",
    "    #                 if item_s not in objective_patterns:      # if possibility of being a subjective one is smaller than threshold,\n",
    "    #                     objective_patterns.append(item_s)     # the current item will be selected as a objective pattern   \n",
    "\n",
    "            for item_o, percentage_O in all_O_percentages:\n",
    "\n",
    "                if percentage_O >= threshold:  \n",
    "                    if item_o not in objective_patterns:      # if possibility of being a objective one is larger than threshold,\n",
    "                        objective_patterns.append(item_o)     # the current item will be selected as a objective pattern \n",
    "\n",
    "    #             if percentage_O <= 0.5: \n",
    "    #                 if item_o not in subjective_patterns:      # if possibility of being a objective one is smaller than threshold,\n",
    "    #                     subjective_patterns.append(item_o)    # the current item will be selected as a subjective pattern  \n",
    "\n",
    "            Sub_positive = 0\n",
    "            Obj_positive = 0\n",
    "            Sub_negative = 0\n",
    "            Obj_negative = 0\n",
    "            for a in testing_S_data:\n",
    "                if a in subjective_patterns:\n",
    "                    Sub_positive += 1\n",
    "                elif a in objective_patterns:\n",
    "                    Sub_negative += 1\n",
    "                else:\n",
    "                    continue\n",
    "            for a in testing_O_data:\n",
    "                if a in subjective_patterns:\n",
    "                    Obj_negative += 1\n",
    "                elif a in objective_patterns:\n",
    "                    Obj_positive += 1\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "            try:\n",
    "                accuracy = (float(Sub_positive + Obj_positive))/(Sub_positive + Sub_negative + Obj_positive + Obj_negative)\n",
    "                precision_S = (float(Sub_positive))/(Sub_positive + Obj_negative)\n",
    "                precision_O = (float(Obj_positive))/(Obj_positive + Sub_negative)\n",
    "                Recall_S = (float(Sub_positive))/(Sub_positive + Sub_negative)\n",
    "                Recall_O = (float(Obj_positive))/(Obj_positive + Obj_negative)\n",
    "                Fscore_S = (2*Recall_S*precision_S)/(Recall_S+precision_S)\n",
    "                Fscore_O = (2*Recall_O*precision_O)/(Recall_O+precision_O)\n",
    "                count_sub += 1\n",
    "            except:\n",
    "                continue\n",
    "    #         print accuracy, Sub_positive, Obj_positive, Sub_negative, Obj_negative    \n",
    "            subjective_result.append(accuracy)\n",
    "            precision_S_all.append(precision_S)\n",
    "            precision_O_all.append(precision_O)\n",
    "            recall_S_all.append(Recall_S)\n",
    "            recall_O_all.append(Recall_O)\n",
    "            fscore_S_all.append(Fscore_S)\n",
    "            fscore_O_all.append(Fscore_O)\n",
    "#             print ('all_S_percentages', all_S_percentages)\n",
    "#             print ('all_O_percentages', all_O_percentages)\n",
    "#             break\n",
    "#     #     subjective_result.append(sub_accuracy/count_sub)\n",
    "#     #     objective_result.append(obj_accuracy/count_obj)\n",
    "#         break\n",
    "    print 'when the threshold = ', threshold\n",
    "#     print  subjective_result\n",
    "    tb.field_names = [\"Measure\", \"Mean\", \"variance\", \"standard deviation\"]\n",
    "    #print ['accuracy',round(np.mean(subjective_result),5), round(np.var(subjective_result),5), round(np.std(subjective_result),2)]\n",
    "    tb.add_row(['accuracy',round(np.mean(subjective_result),5), round(np.var(subjective_result),5), round(np.std(subjective_result),5)])\n",
    "    tb.add_row(['precision_S_all',round(np.mean(precision_S_all),5), round(np.var(precision_S_all),5), round(np.std(precision_S_all),5)])\n",
    "    tb.add_row(['precision_O_all',round(np.mean(precision_O_all),5), round(np.var(precision_O_all),5),round(np.std(precision_O_all),5)])\n",
    "    tb.add_row(['recall_S_all',round(np.mean(recall_S_all),5), round(np.var(recall_S_all),5), round(np.std(recall_S_all),5)])\n",
    "    tb.add_row(['recall_O_all',round(np.mean(recall_O_all),5), round(np.var(recall_O_all),5), round(np.std(recall_O_all),5)])\n",
    "    tb.add_row(['fscore_S_all',round(np.mean(fscore_S_all),5), round(np.var(fscore_S_all),5), round(np.std(fscore_S_all),5)])\n",
    "    tb.add_row(['fscore_O_all',round(np.mean(fscore_O_all),5), round(np.var(fscore_O_all),5), round(np.std(fscore_O_all),5)])\n",
    "    tb.add_row(['average precision', round(float(np.mean(precision_S_all)+np.mean(precision_O_all))/2,5), round(float(np.var(precision_S_all)+np.var(precision_O_all))/2,5), round(float(np.std(precision_S_all)+np.std(precision_O_all))/2,5)])\n",
    "    tb.add_row(['average recall', round(float(np.mean(recall_S_all)+np.mean(recall_O_all))/2,5), round(float(np.var(recall_S_all)+np.var(recall_O_all))/2,5), round(float(np.std(recall_S_all)+np.std(recall_O_all))/2,5)])\n",
    "    tb.add_row(['average fscore', round(float(np.mean(fscore_S_all)+np.mean(fscore_O_all))/2,5), round(float(np.var(fscore_S_all)+np.var(fscore_O_all))/2,5), round(float(np.std(fscore_S_all)+np.std(fscore_O_all))/2,5)])\n",
    "    print (tb)\n",
    "\n",
    "\n",
    "#print (subjective_result)\n",
    "# print (objective_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when the threshold =  0.7\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     |  0.7646 | 0.00082  |      0.02864       |\n",
    "|  precision_S_all  | 0.77369 | 0.00985  |      0.09923       |\n",
    "|  precision_O_all  |  0.764  | 0.00084  |      0.02898       |\n",
    "|    recall_S_all   | 0.25333 | 0.00515  |      0.07176       |\n",
    "|    recall_O_all   | 0.96992 | 0.00024  |      0.01553       |\n",
    "|    fscore_S_all   | 0.37666 | 0.00706  |      0.08404       |\n",
    "|    fscore_O_all   | 0.85439 | 0.00037  |      0.01927       |\n",
    "| average precision | 0.76885 | 0.00534  |      0.06411       |\n",
    "|   average recall  | 0.61163 |  0.0027  |      0.04365       |\n",
    "|   average fscore  | 0.61552 | 0.00372  |      0.05165       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.725\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.79999 | 0.00173  |      0.04157       |\n",
    "|  precision_S_all  | 0.76385 | 0.01117  |       0.1057       |\n",
    "|  precision_O_all  | 0.80737 | 0.00201  |      0.04482       |\n",
    "|    recall_S_all   | 0.40509 | 0.01434  |      0.11974       |\n",
    "|    recall_O_all   | 0.95167 | 0.00069  |      0.02626       |\n",
    "|    fscore_S_all   | 0.51882 | 0.01309  |      0.11443       |\n",
    "|    fscore_O_all   | 0.87271 | 0.00077  |      0.02781       |\n",
    "| average precision | 0.78561 | 0.00659  |      0.07526       |\n",
    "|   average recall  | 0.67838 | 0.00751  |       0.073        |\n",
    "|   average fscore  | 0.69576 | 0.00693  |      0.07112       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.75\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.81192 | 0.00148  |      0.03852       |\n",
    "|  precision_S_all  | 0.77353 | 0.01274  |      0.11289       |\n",
    "|  precision_O_all  | 0.82009 | 0.00152  |      0.03904       |\n",
    "|    recall_S_all   | 0.42838 | 0.01059  |       0.1029       |\n",
    "|    recall_O_all   | 0.95182 | 0.00081  |      0.02848       |\n",
    "|    fscore_S_all   | 0.54329 | 0.00933  |       0.0966       |\n",
    "|    fscore_O_all   | 0.88044 | 0.00073  |      0.02702       |\n",
    "| average precision | 0.79681 | 0.00713  |      0.07596       |\n",
    "|   average recall  |  0.6901 |  0.0057  |      0.06569       |\n",
    "|   average fscore  | 0.71186 | 0.00503  |      0.06181       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.775\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.82339 |  0.0018  |      0.04237       |\n",
    "|  precision_S_all  | 0.79912 | 0.01366  |      0.11688       |\n",
    "|  precision_O_all  | 0.82866 | 0.00205  |      0.04529       |\n",
    "|    recall_S_all   | 0.44774 | 0.01352  |      0.11628       |\n",
    "|    recall_O_all   | 0.95849 | 0.00075  |      0.02737       |\n",
    "|    fscore_S_all   | 0.56459 | 0.01142  |      0.10688       |\n",
    "|    fscore_O_all   | 0.88803 | 0.00084  |      0.02906       |\n",
    "| average precision | 0.81389 | 0.00786  |      0.08109       |\n",
    "|   average recall  | 0.70311 | 0.00713  |      0.07182       |\n",
    "|   average fscore  | 0.72631 | 0.00613  |      0.06797       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.8\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.82406 | 0.00208  |      0.04561       |\n",
    "|  precision_S_all  | 0.80763 | 0.01574  |      0.12545       |\n",
    "|  precision_O_all  | 0.82896 | 0.00247  |      0.04974       |\n",
    "|    recall_S_all   |  0.4726 | 0.01868  |      0.13669       |\n",
    "|    recall_O_all   | 0.95499 | 0.00109  |      0.03294       |\n",
    "|    fscore_S_all   | 0.58312 | 0.01466  |      0.12107       |\n",
    "|    fscore_O_all   | 0.88647 | 0.00104  |      0.03231       |\n",
    "| average precision | 0.81829 | 0.00911  |      0.08759       |\n",
    "|   average recall  | 0.71379 | 0.00988  |      0.08482       |\n",
    "|   average fscore  |  0.7348 | 0.00785  |      0.07669       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.825\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.83697 | 0.00278  |      0.05277       |\n",
    "|  precision_S_all  | 0.76507 | 0.02698  |      0.16427       |\n",
    "|  precision_O_all  | 0.85432 | 0.00317  |       0.0563       |\n",
    "|    recall_S_all   | 0.45673 | 0.03141  |      0.17724       |\n",
    "|    recall_O_all   | 0.94967 | 0.00179  |      0.04227       |\n",
    "|    fscore_S_all   | 0.54541 |  0.0224  |      0.14968       |\n",
    "|    fscore_O_all   | 0.89801 | 0.00135  |      0.03674       |\n",
    "| average precision | 0.80969 | 0.01508  |      0.11028       |\n",
    "|   average recall  |  0.7032 |  0.0166  |      0.10976       |\n",
    "|   average fscore  | 0.72171 | 0.01188  |      0.09321       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.85\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.85808 | 0.00409  |      0.06393       |\n",
    "|  precision_S_all  | 0.67052 | 0.04832  |      0.21981       |\n",
    "|  precision_O_all  | 0.88997 | 0.00423  |      0.06505       |\n",
    "|    recall_S_all   | 0.45108 | 0.05378  |       0.2319       |\n",
    "|    recall_O_all   | 0.94601 | 0.00221  |      0.04697       |\n",
    "|    fscore_S_all   | 0.49321 | 0.02757  |      0.16604       |\n",
    "|    fscore_O_all   | 0.91535 | 0.00177  |      0.04209       |\n",
    "| average precision | 0.78024 | 0.02627  |      0.14243       |\n",
    "|   average recall  | 0.69855 | 0.02799  |      0.13944       |\n",
    "|   average fscore  | 0.70428 | 0.01467  |      0.10406       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.875\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.86316 | 0.00344  |      0.05866       |\n",
    "|  precision_S_all  | 0.51537 | 0.01807  |      0.13444       |\n",
    "|  precision_O_all  | 0.91032 |  0.0033  |      0.05745       |\n",
    "|    recall_S_all   | 0.48395 | 0.05388  |      0.23212       |\n",
    "|    recall_O_all   | 0.93169 |  0.0014  |      0.03742       |\n",
    "|    fscore_S_all   | 0.47338 |  0.0229  |      0.15132       |\n",
    "|    fscore_O_all   | 0.91975 | 0.00142  |      0.03766       |\n",
    "| average precision | 0.71284 | 0.01069  |      0.09595       |\n",
    "|   average recall  | 0.70782 | 0.02764  |      0.13477       |\n",
    "|   average fscore  | 0.69656 | 0.01216  |      0.09449       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.9\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.87568 | 0.00299  |      0.05472       |\n",
    "|  precision_S_all  | 0.57292 | 0.01319  |      0.11483       |\n",
    "|  precision_O_all  |  0.9172 | 0.00314  |      0.05604       |\n",
    "|    recall_S_all   | 0.52982 |  0.0568  |      0.23832       |\n",
    "|    recall_O_all   | 0.93902 | 0.00217  |      0.04655       |\n",
    "|    fscore_S_all   |  0.5276 | 0.02343  |      0.15307       |\n",
    "|    fscore_O_all   | 0.92628 | 0.00167  |      0.04084       |\n",
    "| average precision | 0.74506 | 0.00816  |      0.08544       |\n",
    "|   average recall  | 0.73442 | 0.02948  |      0.14243       |\n",
    "|   average fscore  | 0.72694 | 0.01255  |      0.09696       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.925\n",
    "+-------------------+------+----------+--------------------+\n",
    "|      Measure      | Mean | variance | standard deviation |\n",
    "+-------------------+------+----------+--------------------+\n",
    "|      accuracy     | nan  |   nan    |        nan         |\n",
    "|  precision_S_all  | nan  |   nan    |        nan         |\n",
    "|  precision_O_all  | nan  |   nan    |        nan         |\n",
    "|    recall_S_all   | nan  |   nan    |        nan         |\n",
    "|    recall_O_all   | nan  |   nan    |        nan         |\n",
    "|    fscore_S_all   | nan  |   nan    |        nan         |\n",
    "|    fscore_O_all   | nan  |   nan    |        nan         |\n",
    "| average precision | nan  |   nan    |        nan         |\n",
    "|   average recall  | nan  |   nan    |        nan         |\n",
    "|   average fscore  | nan  |   nan    |        nan         |\n",
    "+-------------------+------+----------+--------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before modifying the experiment\n",
    "\n",
    "when the threshold =  0.7\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.79116 | 0.00151  |      0.03887       |\n",
    "|  precision_S_all  | 0.78521 | 0.00993  |      0.09966       |\n",
    "|  precision_O_all  | 0.79474 | 0.00163  |       0.0404       |\n",
    "|    recall_S_all   |  0.4562 | 0.00884  |      0.09399       |\n",
    "|    recall_O_all   | 0.94041 | 0.00125  |      0.03541       |\n",
    "|    fscore_S_all   | 0.56982 | 0.00682  |      0.08257       |\n",
    "|    fscore_O_all   | 0.86068 | 0.00086  |      0.02938       |\n",
    "| average precision | 0.78998 | 0.00578  |      0.07003       |\n",
    "|   average recall  |  0.6983 | 0.00504  |       0.0647       |\n",
    "|   average fscore  | 0.71525 | 0.00384  |      0.05598       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.725\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.79595 | 0.00153  |      0.03913       |\n",
    "|  precision_S_all  | 0.80506 | 0.01137  |      0.10664       |\n",
    "|  precision_O_all  | 0.79594 | 0.00167  |      0.04083       |\n",
    "|    recall_S_all   |  0.4179 |  0.0108  |      0.10392       |\n",
    "|    recall_O_all   | 0.95463 |  0.001   |       0.0317       |\n",
    "|    fscore_S_all   | 0.54141 | 0.00954  |      0.09769       |\n",
    "|    fscore_O_all   | 0.86733 | 0.00081  |      0.02847       |\n",
    "| average precision |  0.8005 | 0.00652  |      0.07374       |\n",
    "|   average recall  | 0.68626 |  0.0059  |      0.06781       |\n",
    "|   average fscore  | 0.70437 | 0.00518  |      0.06308       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.75\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.81992 | 0.00216  |      0.04646       |\n",
    "|  precision_S_all  | 0.82353 | 0.01244  |      0.11153       |\n",
    "|  precision_O_all  | 0.82092 | 0.00272  |      0.05211       |\n",
    "|    recall_S_all   | 0.50497 | 0.01616  |      0.12712       |\n",
    "|    recall_O_all   | 0.95243 | 0.00111  |      0.03327       |\n",
    "|    fscore_S_all   | 0.61531 | 0.01182  |      0.10871       |\n",
    "|    fscore_O_all   | 0.88061 | 0.00111  |      0.03325       |\n",
    "| average precision | 0.82223 | 0.00758  |      0.08182       |\n",
    "|   average recall  |  0.7287 | 0.00863  |       0.0802       |\n",
    "|   average fscore  | 0.74796 | 0.00646  |      0.07098       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.775\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.83345 | 0.00206  |      0.04542       |\n",
    "|  precision_S_all  | 0.84618 | 0.01247  |      0.11167       |\n",
    "|  precision_O_all  |  0.8324 |  0.0023  |      0.04797       |\n",
    "|    recall_S_all   | 0.51211 | 0.01482  |      0.12172       |\n",
    "|    recall_O_all   | 0.96058 | 0.00105  |      0.03233       |\n",
    "|    fscore_S_all   | 0.62838 | 0.01162  |       0.1078       |\n",
    "|    fscore_O_all   | 0.89101 | 0.00106  |      0.03253       |\n",
    "| average precision | 0.83929 | 0.00739  |      0.07982       |\n",
    "|   average recall  | 0.73634 | 0.00793  |      0.07703       |\n",
    "|   average fscore  |  0.7597 | 0.00634  |      0.07016       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.8\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.83183 | 0.00203  |      0.04505       |\n",
    "|  precision_S_all  | 0.84887 |  0.0143  |       0.1196       |\n",
    "|  precision_O_all  | 0.82976 | 0.00238  |      0.04879       |\n",
    "|    recall_S_all   | 0.49641 | 0.01654  |      0.12862       |\n",
    "|    recall_O_all   | 0.96287 | 0.00103  |      0.03215       |\n",
    "|    fscore_S_all   | 0.61528 |  0.0134  |      0.11576       |\n",
    "|    fscore_O_all   | 0.89039 | 0.00104  |       0.0323       |\n",
    "| average precision | 0.83932 | 0.00834  |       0.0842       |\n",
    "|   average recall  | 0.72964 | 0.00879  |      0.08039       |\n",
    "|   average fscore  | 0.75283 | 0.00722  |      0.07403       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.825\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.82554 | 0.00269  |      0.05191       |\n",
    "|  precision_S_all  | 0.87793 | 0.01288  |      0.11351       |\n",
    "|  precision_O_all  | 0.81613 |  0.0033  |       0.0574       |\n",
    "|    recall_S_all   | 0.53409 | 0.02363  |      0.15371       |\n",
    "|    recall_O_all   |  0.9594 | 0.00179  |      0.04235       |\n",
    "|    fscore_S_all   | 0.64848 | 0.01672  |      0.12929       |\n",
    "|    fscore_O_all   | 0.88052 | 0.00151  |      0.03887       |\n",
    "| average precision | 0.84703 | 0.00809  |      0.08546       |\n",
    "|   average recall  | 0.74675 | 0.01271  |      0.09803       |\n",
    "|   average fscore  |  0.7645 | 0.00911  |      0.08408       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.85\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.86181 | 0.00453  |       0.0673       |\n",
    "|  precision_S_all  | 0.92759 | 0.01254  |      0.11199       |\n",
    "|  precision_O_all  | 0.84418 | 0.00659  |      0.08119       |\n",
    "|    recall_S_all   | 0.64902 | 0.03265  |      0.18069       |\n",
    "|    recall_O_all   | 0.97158 | 0.00201  |       0.0448       |\n",
    "|    fscore_S_all   | 0.74722 | 0.02015  |      0.14194       |\n",
    "|    fscore_O_all   | 0.90074 | 0.00261  |       0.0511       |\n",
    "| average precision | 0.88589 | 0.00957  |      0.09659       |\n",
    "|   average recall  |  0.8103 | 0.01733  |      0.11275       |\n",
    "|   average fscore  | 0.82398 | 0.01138  |      0.09652       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.875\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.89432 |  0.008   |      0.08946       |\n",
    "|  precision_S_all  | 0.94414 | 0.01059  |      0.10293       |\n",
    "|  precision_O_all  | 0.87098 | 0.01659  |      0.12879       |\n",
    "|    recall_S_all   | 0.81061 | 0.03788  |      0.19463       |\n",
    "|    recall_O_all   | 0.95297 | 0.00945  |       0.0972       |\n",
    "|    fscore_S_all   |  0.8565 | 0.01907  |       0.1381       |\n",
    "|    fscore_O_all   |  0.9023 | 0.00842  |      0.09177       |\n",
    "| average precision | 0.90756 | 0.01359  |      0.11586       |\n",
    "|   average recall  | 0.88179 | 0.02366  |      0.14591       |\n",
    "|   average fscore  |  0.8794 | 0.01375  |      0.11493       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.9\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.91035 | 0.00986  |      0.09927       |\n",
    "|  precision_S_all  | 0.95383 | 0.01062  |      0.10307       |\n",
    "|  precision_O_all  | 0.88452 | 0.02476  |      0.15735       |\n",
    "|    recall_S_all   | 0.87896 | 0.02634  |       0.1623       |\n",
    "|    recall_O_all   | 0.94362 | 0.01633  |      0.12779       |\n",
    "|    fscore_S_all   | 0.90309 | 0.01384  |      0.11764       |\n",
    "|    fscore_O_all   | 0.89903 | 0.01496  |       0.1223       |\n",
    "| average precision | 0.91917 | 0.01769  |      0.13021       |\n",
    "|   average recall  | 0.91129 | 0.02134  |      0.14505       |\n",
    "|   average fscore  | 0.90106 |  0.0144  |      0.11997       |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "when the threshold =  0.925\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      Measure      |   Mean  | variance | standard deviation |\n",
    "+-------------------+---------+----------+--------------------+\n",
    "|      accuracy     | 0.79571 | 0.00679  |      0.08241       |\n",
    "|  precision_S_all  |  0.9534 | 0.01175  |      0.10839       |\n",
    "|  precision_O_all  | 0.64954 | 0.01183  |      0.10875       |\n",
    "|    recall_S_all   | 0.69516 | 0.01881  |      0.13716       |\n",
    "|    recall_O_all   | 0.95254 | 0.01166  |      0.10798       |\n",
    "|    fscore_S_all   | 0.79508 |  0.0137  |      0.11706       |\n",
    "|    fscore_O_all   | 0.76398 | 0.00905  |      0.09516       |\n",
    "| average precision | 0.80147 | 0.01179  |      0.10857       |\n",
    "|   average recall  | 0.82385 | 0.01524  |      0.12257       |\n",
    "|   average fscore  | 0.77953 | 0.01138  |      0.10611       |\n",
    "+-------------------+---------+----------+--------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of testing data 670\n",
      "# of true positives 31\n",
      "# of false positives 9\n",
      "# of true negatives 411\n",
      "# of false negatives 219\n",
      "0.659701492537\n",
      "31 411 40 630\n",
      "# of testing data 669\n",
      "# of true positives 23\n",
      "# of false positives 17\n",
      "# of true negatives 403\n",
      "# of false negatives 226\n",
      "0.636771300448\n",
      "23 403 40 629\n",
      "# of testing data 670\n",
      "# of true positives 32\n",
      "# of false positives 8\n",
      "# of true negatives 412\n",
      "# of false negatives 218\n",
      "0.662686567164\n",
      "32 412 40 630\n",
      "# of testing data 669\n",
      "# of true positives 23\n",
      "# of false positives 17\n",
      "# of true negatives 403\n",
      "# of false negatives 226\n",
      "0.636771300448\n",
      "23 403 40 629\n",
      "# of testing data 670\n",
      "# of true positives 30\n",
      "# of false positives 9\n",
      "# of true negatives 411\n",
      "# of false negatives 220\n",
      "0.658208955224\n",
      "30 411 39 631\n",
      "# of testing data 670\n",
      "# of true positives 35\n",
      "# of false positives 17\n",
      "# of true negatives 403\n",
      "# of false negatives 215\n",
      "0.653731343284\n",
      "35 403 52 618\n",
      "# of testing data 670\n",
      "# of true positives 35\n",
      "# of false positives 9\n",
      "# of true negatives 411\n",
      "# of false negatives 215\n",
      "0.665671641791\n",
      "35 411 44 626\n",
      "# of testing data 670\n",
      "# of true positives 36\n",
      "# of false positives 17\n",
      "# of true negatives 403\n",
      "# of false negatives 214\n",
      "0.655223880597\n",
      "36 403 53 617\n",
      "# of testing data 670\n",
      "# of true positives 30\n",
      "# of false positives 9\n",
      "# of true negatives 411\n",
      "# of false negatives 220\n",
      "0.658208955224\n",
      "30 411 39 631\n",
      "# of testing data 670\n",
      "# of true positives 28\n",
      "# of false positives 17\n",
      "# of true negatives 403\n",
      "# of false negatives 222\n",
      "0.64328358209\n",
      "28 403 45 625\n",
      "# of testing data 669\n",
      "# of true positives 23\n",
      "# of false positives 9\n",
      "# of true negatives 411\n",
      "# of false negatives 226\n",
      "0.648729446936\n",
      "23 411 32 637\n",
      "# of testing data 670\n",
      "# of true positives 36\n",
      "# of false positives 17\n",
      "# of true negatives 403\n",
      "# of false negatives 214\n",
      "0.655223880597\n",
      "36 403 53 617\n",
      "# of testing data 670\n",
      "# of true positives 24\n",
      "# of false positives 9\n",
      "# of true negatives 411\n",
      "# of false negatives 226\n",
      "0.649253731343\n",
      "24 411 33 637\n",
      "# of testing data 670\n",
      "# of true positives 30\n",
      "# of false positives 17\n",
      "# of true negatives 403\n",
      "# of false negatives 220\n",
      "0.646268656716\n",
      "30 403 47 623\n",
      "# of testing data 670\n",
      "# of true positives 31\n",
      "# of false positives 9\n",
      "# of true negatives 411\n",
      "# of false negatives 219\n",
      "0.659701492537\n",
      "31 411 40 630\n",
      "# of testing data 670\n",
      "# of true positives 30\n",
      "# of false positives 17\n",
      "# of true negatives 403\n",
      "# of false negatives 220\n",
      "0.646268656716\n",
      "30 403 47 623\n",
      "# of testing data 670\n",
      "# of true positives 35\n",
      "# of false positives 9\n",
      "# of true negatives 411\n",
      "# of false negatives 215\n",
      "0.665671641791\n",
      "35 411 44 626\n",
      "# of testing data 669\n",
      "# of true positives 23\n",
      "# of false positives 17\n",
      "# of true negatives 403\n",
      "# of false negatives 226\n",
      "0.636771300448\n",
      "23 403 40 629\n",
      "# of testing data 670\n",
      "# of true positives 36\n",
      "# of false positives 9\n",
      "# of true negatives 411\n",
      "# of false negatives 214\n",
      "0.667164179104\n",
      "36 411 45 625\n",
      "# of testing data 670\n",
      "# of true positives 31\n",
      "# of false positives 17\n",
      "# of true negatives 403\n",
      "# of false negatives 219\n",
      "0.64776119403\n",
      "31 403 48 622\n",
      "Accuracy 0.652653659951\n",
      "Precision 0.64947600854\n",
      "Recall 0.969166666667\n",
      "F-score 0.777736323582\n"
     ]
    }
   ],
   "source": [
    "######## cross fold testing##########\n",
    "import math\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "np_S_data = [] #transform string to numpy array for subjective data\n",
    "for a in S_data:\n",
    "\n",
    "    a = [int(b) for b in a.split(', ')]\n",
    "    if len(a) != 3:\n",
    "        del a[2]\n",
    "    if 8 in a:\n",
    "        pass\n",
    "    np_S_data.append(np.array(a))\n",
    "    \n",
    "np_S_data = np.array(np_S_data)\n",
    "np_O_data = [] #transform string to numpy array for objective data\n",
    "\n",
    "for a in O_data:\n",
    "    a = [int(b) for b in a.split(', ')]\n",
    "    if len(a) != 3:\n",
    "        del a[2]\n",
    "    if 8 in a:\n",
    "        pass\n",
    "    np_O_data.append(np.array(a))\n",
    "np_O_data = np.array(np_O_data)\n",
    "\n",
    "len_S_data = int(len(np_S_data))\n",
    "len_O_data = int(len(np_O_data))\n",
    "\n",
    "splitted_S_data = np.array(np.array_split(np_S_data,10,axis=0))\n",
    "splitted_O_data = np.array(np.array_split(np_O_data,10,axis=0))\n",
    "\n",
    "SUM_accuracy = 0\n",
    "SUM_Precision =  0\n",
    "SUM_recall = 0\n",
    "SUM_Fscore = 0\n",
    "\n",
    "#write_csv(path_write, [])\n",
    "\n",
    "for loop_num in range(10):   \n",
    "    splitted_S_data = sorted(splitted_S_data, key=lambda k: random.random())\n",
    "    for fold in range(2):\n",
    "        \n",
    "        testing_S_data = splitted_S_data[fold]\n",
    "        testing_O_data = splitted_O_data[fold]\n",
    "        merged_testing_data = np.vstack((testing_S_data, testing_O_data))\n",
    "#         print ('test', testing_S_data)\n",
    "        label_S_testing = list(np.zeros(testing_S_data.shape[0], dtype = np.int))\n",
    "        label_O_testing = list(np.ones(testing_O_data.shape[0], dtype = np.int))\n",
    "        merged_testing_label = label_S_testing + label_O_testing\n",
    "        training_S_data = None\n",
    "\n",
    "        for a in (np.delete(splitted_S_data, fold)): #concatenate O training data\n",
    "            if training_S_data is None:\n",
    "                training_S_data = a\n",
    "            else:\n",
    "                training_S_data = np.vstack((training_S_data, a))\n",
    "        training_O_data = None\n",
    "        for a in (np.delete(splitted_O_data, fold)): #concatenate S training data\n",
    "            if training_O_data is None:\n",
    "                training_O_data = a\n",
    "            else:\n",
    "                training_O_data = np.vstack((training_O_data, a)) \n",
    "\n",
    "        label_S_training = list(np.zeros(training_S_data.shape[0], dtype = np.int))\n",
    "        label_O_training = list(np.ones(training_O_data.shape[0], dtype = np.int))\n",
    "        clf = svm.SVC()\n",
    "        X = np.vstack((training_S_data, training_O_data))    \n",
    "        y = label_S_training + label_O_training\n",
    "        clf.fit(X, y)\n",
    "\n",
    "    #     print 'Lengthes of training S and O data are', len(label_S_training), len(label_O_training)\n",
    "\n",
    "    #     print 'Lengthes of testing S and O data are',len(testing_S_data), len(testing_O_data)\n",
    "    #     #print X\n",
    "        result = []\n",
    "        for testing_item in merged_testing_data:\n",
    "            #print testing_item\n",
    "            result.append(clf.predict([testing_item])[0])\n",
    "        if len(result) == len(merged_testing_label):\n",
    "            print '# of testing data', len(result)\n",
    "            print '# of true positives', len([i for i, j in zip(result, merged_testing_label) if i == j ==0])\n",
    "            print '# of false positives', result.count(0) - len([i for i, j in zip(result, merged_testing_label) if i == j == 0])\n",
    "            print '# of true negatives', len([i for i, j in zip(result, merged_testing_label) if i == j ==1])\n",
    "            print '# of false negatives', result.count(1) - len([i for i, j in zip(result, merged_testing_label) if i == j ==1])\n",
    "            print float(len([i for i, j in zip(result, merged_testing_label) if i == j]))/len(result)\n",
    "            num_0 = len([i for i, j in zip(result, merged_testing_label) if i == j == 0]) # all detected 0\n",
    "            num_1 = len([i for i, j in zip(result, merged_testing_label) if i == j == 1]) # all detected 1\n",
    "\n",
    "            label_0 = merged_testing_label.count(0) # all label 0\n",
    "            label_1 = merged_testing_label.count(1) # all label 1\n",
    "\n",
    "            result_0 = result.count(0) # all 0 in result\n",
    "            result_1 = result.count(1) # all 1 in result\n",
    "            print num_0,num_1,result_0,result_1\n",
    "            accuracy = float(num_0+num_1)/len(result)\n",
    "\n",
    "            Precision =  float(num_1)/result_1\n",
    "            recall = float(num_1)/label_1\n",
    "#             Precision =  float(num_0)/result_0\n",
    "#             recall = float(num_0)/label_0\n",
    "            Fscore = (2*Precision*recall)/(recall+Precision)\n",
    "\n",
    "\n",
    "            SUM_accuracy += accuracy\n",
    "            SUM_Precision += Precision\n",
    "            SUM_recall += recall\n",
    "            SUM_Fscore += Fscore\n",
    "\n",
    "\n",
    "        else:\n",
    "            print 'exception'\n",
    "        \n",
    "print 'Accuracy', SUM_accuracy/20\n",
    "print 'Precision', SUM_Precision/20\n",
    "print 'Recall', SUM_recall/20\n",
    "print 'F-score', SUM_Fscore/20\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
